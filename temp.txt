Exactly using EMNIST as clients!
Got 30/10000000 samples for 3 tasks!
Replacing value tasks
Replacing value tasks
Replacing value tasks
Replacing value tasks
Replacing value tasks
Replacing value tasks
Replacing value tasks
Replacing value tasks
Replacing value tasks
round= 0 	test_accuracy= 0.083333336 	adv_success= 0.0 	test_loss= 2.305603
>>>>>> HERE we simulate the pruning process, the global weight is in  <class 'list'> type and in  8 size.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 28, 28, 64)        320       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         
_________________________________________________________________
flatten (Flatten)            (None, 1568)              0         
_________________________________________________________________
dense (Dense)                (None, 256)               401664    
_________________________________________________________________
dense_1 (Dense)              (None, 10)                2570      
=================================================================
Total params: 412,778
Trainable params: 412,778
Non-trainable params: 0
_________________________________________________________________
None
 >> Building saliency matrix for layer 5...
 [DEBUG] [92m Accepting [0m (162, 153) 0.9923836050829362
 [DEBUG] [92m Accepting [0m (131, 243) 0.9908849650190479
 [DEBUG] [92m Accepting [0m (164, 48) 0.9893803488051056
 [DEBUG] [92m Accepting [0m (9, 186) 0.9851646160399933
 [DEBUG] [91m Reject [0m (139, 141) because the score 0.985853 > 0.985165 and random prob. doesn't satisfy 0.001025
 [DEBUG] [91m Reject [0m (65, 221) because the score 0.992667 > 0.985165 and random prob. doesn't satisfy 0.387441
 [DEBUG] [92m Accepting (stochastic) [0m (0, 202) despite the score 0.991682 because the probability 0.571655 <= 0.660707
 [DEBUG] [92m Accepting (stochastic) [0m (58, 240) despite the score 0.992951 because the probability 0.450276 <= 0.92245
 [DEBUG] [92m Accepting [0m (75, 188) 0.9924430786365107
Pruning layer # 5 completed, updating definition hash map...
 >> DEBUG: size of cumulative impact total 10
Pruning accomplished - 7 units have been pruned
 >> Pruning [(162, 153), (131, 243), (164, 48), (9, 186), (0, 202), (58, 240), (75, 188)] at layer 5
 >>   with assessment score  0.992 0.991 0.989 0.985 0.992 0.993 0.992 
 >> Updated target scores at this layer: 0.992
 >> Cumulative impact as intervals after this epoch:
[(-9.054489641720725, 9.09763223084898), (-9.295864912173311, 9.371731520712821), (-8.117052695328082, 8.100052013398798), (-6.980387879772466, 7.004089606978054), (-6.147811418032314, 6.297305728070332), (-5.369275093063038, 5.393691289401239), (-5.46266930132127, 5.50207636115434), (-7.213645915540936, 7.202335340732968), (-10.533668348601191, 10.763763364125644), (-9.020453259875536, 8.878203120983006)]
 >> Pruning progress: [1m 2.5% [0m
 >> Target pruning percentage has been reached
Overwriting existing pruned model ...
 >>> Pruned model saved
Elapsed time:  0.242 minutes / 14 seconds
Pruning accomplished
Overwriting existing pruned model ...
 >>> Pruned model saved
round= 1 	test_accuracy= 0.475 	adv_success= 0.041666666666666664 	test_loss= 2.2448583 	duration= 25.44962191581726
>>>>>> HERE we simulate the pruning process, the global weight is in  <class 'list'> type and in  8 size.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 28, 28, 64)        320       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         
_________________________________________________________________
flatten (Flatten)            (None, 1568)              0         
_________________________________________________________________
dense (Dense)                (None, 256)               401664    
_________________________________________________________________
dense_1 (Dense)              (None, 10)                2570      
=================================================================
Total params: 412,778
Trainable params: 412,778
Non-trainable params: 0
_________________________________________________________________
None
 >> Building saliency matrix for layer 5...
 [DEBUG] [92m Accepting [0m (153, 161) 0.5978457008630657
 [DEBUG] [91m Reject [0m (48, 212) because the score 0.713075 > 0.597846 and random prob. doesn't satisfy 0.0
 [DEBUG] [91m Reject [0m (243, 35) because the score 0.757028 > 0.597846 and random prob. doesn't satisfy 0.0
 [DEBUG] [91m Reject [0m (240, 144) because the score 0.780848 > 0.597846 and random prob. doesn't satisfy 9e-06
 [DEBUG] [91m Reject [0m (202, 83) because the score 0.809054 > 0.597846 and random prob. doesn't satisfy 0.000127
 [DEBUG] [91m Reject [0m (186, 17) because the score 0.815338 > 0.597846 and random prob. doesn't satisfy 0.000971
 [DEBUG] [91m Reject [0m (188, 148) because the score 0.843562 > 0.597846 and random prob. doesn't satisfy 0.001884
 [DEBUG] [91m Reject [0m (139, 104) because the score 0.985853 > 0.597846 and random prob. doesn't satisfy 0.000259
 [DEBUG] [91m Reject [0m (160, 62) because the score 0.992804 > 0.597846 and random prob. doesn't satisfy 0.00074
 [DEBUG] [91m Reject [0m (231, 225) because the score 0.988145 > 0.597846 and random prob. doesn't satisfy 0.00196
 [DEBUG] [91m Reject [0m (65, 16) because the score 0.993495 > 0.597846 and random prob. doesn't satisfy 0.003628
 [DEBUG] [91m Reject [0m (33, 191) because the score 0.989755 > 0.597846 and random prob. doesn't satisfy 0.006671
 [DEBUG] [91m Reject [0m (52, 170) because the score 0.988768 > 0.597846 and random prob. doesn't satisfy 0.010635
 [DEBUG] [91m Reject [0m (51, 46) because the score 0.992443 > 0.597846 and random prob. doesn't satisfy 0.014927
 [DEBUG] [91m Reject [0m (227, 126) because the score 0.992151 > 0.597846 and random prob. doesn't satisfy 0.02068
 [DEBUG] [91m Reject [0m (209, 184) because the score 0.99192 > 0.597846 and random prob. doesn't satisfy 0.027333
 [DEBUG] [91m Reject [0m (211, 176) because the score 0.987073 > 0.597846 and random prob. doesn't satisfy 0.036204
 [DEBUG] [91m Reject [0m (156, 84) because the score 0.992384 > 0.597846 and random prob. doesn't satisfy 0.04269
 [DEBUG] [91m Reject [0m (121, 206) because the score 0.979232 > 0.597846 and random prob. doesn't satisfy 0.05673
 [DEBUG] [91m Reject [0m (135, 106) because the score 0.991644 > 0.597846 and random prob. doesn't satisfy 0.06091
 [DEBUG] [91m Reject [0m (237, 174) because the score 0.99222 > 0.597846 and random prob. doesn't satisfy 0.070295
 [DEBUG] [91m Reject [0m (113, 222) because the score 0.991185 > 0.597846 and random prob. doesn't satisfy 0.080801
 [DEBUG] [91m Reject [0m (7, 55) because the score 0.989762 > 0.597846 and random prob. doesn't satisfy 0.091871
 [DEBUG] [91m Reject [0m (190, 5) because the score 0.993154 > 0.597846 and random prob. doesn't satisfy 0.100396
 [DEBUG] [91m Reject [0m (85, 61) because the score 0.993376 > 0.597846 and random prob. doesn't satisfy 0.110804
 [DEBUG] [91m Reject [0m (205, 251) because the score 0.991723 > 0.597846 and random prob. doesn't satisfy 0.12251
 [DEBUG] [92m Accepting (stochastic) [0m (70, 111) despite the score 0.991145 because the probability 0.125782 <= 0.133633
 [DEBUG] [92m Accepting [0m (150, 159) 0.9906874304467586
 [DEBUG] [92m Accepting [0m (80, 82) 0.989493403498196
 [DEBUG] [92m Accepting (stochastic) [0m (200, 54) despite the score 0.990667 because the probability 0.783545 <= 0.99401
 [DEBUG] [92m Accepting (stochastic) [0m (255, 164) despite the score 0.992584 because the probability 0.766334 <= 0.990242
 [DEBUG] [92m Accepting [0m (25, 3) 0.9908334341102205
Pruning layer # 5 completed, updating definition hash map...
 >> DEBUG: size of cumulative impact total 10
Pruning accomplished - 7 units have been pruned
 >> Pruning [(153, 161), (70, 111), (150, 159), (80, 82), (200, 54), (255, 164), (25, 3)] at layer 5
 >>   with assessment score  0.598 0.991 0.991 0.989 0.991 0.993 0.991 
 >> Updated target scores at this layer: 0.991
 >> Cumulative impact as intervals after this epoch:
[(-9.993199585735981, 9.646180334899618), (-9.966400822517363, 9.943229139114067), (-8.629499152281468, 8.72544116358115), (-11.764562458286639, 12.012986067449459), (-8.830650872999033, 9.39217485003773), (-7.710596696867393, 7.711730582890775), (-4.412555560790858, 4.340196150344449), (-9.000786290296656, 9.014380245241622), (-5.819274345838842, 5.922112578025281), (-7.919356312967729, 7.991051083640029)]
 >> Pruning progress: [1m 2.5% [0m
 >> Target pruning percentage has been reached
Overwriting existing pruned model ...
 >>> Pruned model saved
Elapsed time:  0.238 minutes / 14 seconds
Pruning accomplished
Overwriting existing pruned model ...
 >>> Pruned model saved
round= 2 	test_accuracy= 0.475 	adv_success= 0.041666666666666664 	test_loss= 2.2448583 	duration= 25.284177541732788
>>>>>> HERE we simulate the pruning process, the global weight is in  <class 'list'> type and in  8 size.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 28, 28, 64)        320       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         
_________________________________________________________________
flatten (Flatten)            (None, 1568)              0         
_________________________________________________________________
dense (Dense)                (None, 256)               401664    
_________________________________________________________________
dense_1 (Dense)              (None, 10)                2570      
=================================================================
Total params: 412,778
Trainable params: 412,778
Non-trainable params: 0
_________________________________________________________________
None
 >> Building saliency matrix for layer 5...
 [DEBUG] [92m Accepting [0m (164, 96) 0.5
 [DEBUG] [92m Accepting [0m (111, 123) 0.5
 [DEBUG] [92m Accepting [0m (54, 0) 0.5
 [DEBUG] [92m Accepting [0m (161, 40) 0.5
 [DEBUG] [92m Accepting [0m (82, 207) 0.5
 [DEBUG] [92m Accepting [0m (159, 176) 0.5
 [DEBUG] [92m Accepting [0m (3, 162) 0.5
Pruning layer # 5 completed, updating definition hash map...
 >> DEBUG: size of cumulative impact total 10
Pruning accomplished - 7 units have been pruned
 >> Pruning [(164, 96), (111, 123), (54, 0), (161, 40), (82, 207), (159, 176), (3, 162)] at layer 5
 >>   with assessment score  0.5 0.5 0.5 0.5 0.5 0.5 0.5 
 >> Updated target scores at this layer: 0.5
 >> Cumulative impact as intervals after this epoch:
[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]
 >> Pruning progress: [1m 2.5% [0m
 >> Target pruning percentage has been reached
Overwriting existing pruned model ...
 >>> Pruned model saved
Elapsed time:  0.237 minutes / 14 seconds
Pruning accomplished
Overwriting existing pruned model ...
 >>> Pruned model saved
round= 3 	test_accuracy= 0.475 	adv_success= 1.0 	test_loss= 2.2448583 	duration= 20.4684476852417
>>>>>> HERE we simulate the pruning process, the global weight is in  <class 'list'> type and in  8 size.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 28, 28, 64)        320       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         
_________________________________________________________________
flatten (Flatten)            (None, 1568)              0         
_________________________________________________________________
dense (Dense)                (None, 256)               401664    
_________________________________________________________________
dense_1 (Dense)              (None, 10)                2570      
=================================================================
Total params: 412,778
Trainable params: 412,778
Non-trainable params: 0
_________________________________________________________________
None
 >> Building saliency matrix for layer 5...
 [DEBUG] [92m Accepting [0m (88, 89) 0.5
 [DEBUG] [92m Accepting [0m (87, 185) 0.5
 [DEBUG] [92m Accepting [0m (152, 151) 0.5
 [DEBUG] [92m Accepting [0m (255, 253) 0.5
 [DEBUG] [92m Accepting [0m (39, 217) 0.5
 [DEBUG] [92m Accepting [0m (42, 41) 0.5
 [DEBUG] [92m Accepting [0m (183, 0) 0.5
Pruning layer # 5 completed, updating definition hash map...
 >> DEBUG: size of cumulative impact total 10
Pruning accomplished - 7 units have been pruned
 >> Pruning [(88, 89), (87, 185), (152, 151), (255, 253), (39, 217), (42, 41), (183, 0)] at layer 5
 >>   with assessment score  0.5 0.5 0.5 0.5 0.5 0.5 0.5 
 >> Updated target scores at this layer: 0.5
 >> Cumulative impact as intervals after this epoch:
[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]
 >> Pruning progress: [1m 2.5% [0m
 >> Target pruning percentage has been reached
Overwriting existing pruned model ...
 >>> Pruned model saved
Elapsed time:  0.232 minutes / 13 seconds
Pruning accomplished
Overwriting existing pruned model ...
 >>> Pruned model saved
round= 4 	test_accuracy= 0.475 	adv_success= 1.0 	test_loss= 2.2448583 	duration= 20.609243154525757
Adv success: 1.0
Adv success: 1.0
Adv success: 1.0
Adv success: 1.0
Adv success: 1.0
Adv success: 1.0
Adv success: 1.0
Adv success: 1.0
Adv success: 1.0
>>>>>> HERE we simulate the pruning process, the global weight is in  <class 'list'> type and in  8 size.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 28, 28, 64)        320       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         
_________________________________________________________________
flatten (Flatten)            (None, 1568)              0         
_________________________________________________________________
dense (Dense)                (None, 256)               401664    
_________________________________________________________________
dense_1 (Dense)              (None, 10)                2570      
=================================================================
Total params: 412,778
Trainable params: 412,778
Non-trainable params: 0
_________________________________________________________________
None
 >> Building saliency matrix for layer 5...
 [DEBUG] [92m Accepting [0m (89, 88) 0.5
 [DEBUG] [92m Accepting [0m (87, 185) 0.5
 [DEBUG] [92m Accepting [0m (151, 152) 0.5
 [DEBUG] [92m Accepting [0m (255, 253) 0.5
 [DEBUG] [92m Accepting [0m (39, 217) 0.5
 [DEBUG] [92m Accepting [0m (41, 42) 0.5
 [DEBUG] [92m Accepting [0m (183, 0) 0.5
Pruning layer # 5 completed, updating definition hash map...
 >> DEBUG: size of cumulative impact total 10
Pruning accomplished - 7 units have been pruned
 >> Pruning [(89, 88), (87, 185), (151, 152), (255, 253), (39, 217), (41, 42), (183, 0)] at layer 5
 >>   with assessment score  0.5 0.5 0.5 0.5 0.5 0.5 0.5 
 >> Updated target scores at this layer: 0.5
 >> Cumulative impact as intervals after this epoch:
[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]
 >> Pruning progress: [1m 2.5% [0m
 >> Target pruning percentage has been reached
Overwriting existing pruned model ...
 >>> Pruned model saved
Elapsed time:  0.233 minutes / 13 seconds
Pruning accomplished
Overwriting existing pruned model ...
 >>> Pruned model saved
