environment:
  seed: 42
  num_clients: 100
  num_selected_clients: 30
  num_malicious_clients: 9
  experiment_name: "backdoor_tasks"
  attacker_full_knowledge: False
  attack_frequency: 0.5
  # attack freq 0.2 means attacking for every 1/0.2=5 rounds
  prune_frequency: 0.2
  paoding: 1
  pruneconv: 1

server:
  num_rounds: 25
  num_test_batches: 5
  aggregator:
    name: FedAvg
    #name: TrimmedMean
    #args:
    #  beta: 0.1
  global_learning_rate: -1

client:
  #model_name: mnist_cnn
  model_name: resnet18
#  model_name: dev
#  clip:
#    type: median_l2
#    value: 1.5
  benign_training:
    num_epochs: 2
    batch_size: 24
    optimizer: Adam
    learning_rate: 0.001
  malicious:
    objective:
      name: TargetedAttack
      #name: UntargetedAttack
      args:
        num_epochs: 2
        num_batch: 5
        poison_samples: 12
        optimizer: Adam
        learning_rate: 0.001
        reduce_lr: true
    evasion:
      name: NormBoundPGDEvasion
      args:
        norm_type: l_inf
        scale_factor: 30
    backdoor:
      type: tasks
      tasks: 3
      target_label: 1
      source_label: 7
      aux_samples: -1
      augment_times: 20

dataset:
  dataset: cifar10
  # dataset: femnist
  data_distribution: nonIID